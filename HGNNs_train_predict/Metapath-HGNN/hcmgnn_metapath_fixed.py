#!/usr/bin/env python3
"""
åŸºäºHCMGNNæ¶æ„çš„å…ƒè·¯å¾„å¼‚è´¨å›¾ç¥ç»ç½‘ç»œæ¨¡å‹
ç»“åˆå…ƒè·¯å¾„æå–å’ŒHCMGNNçš„æ¶æ„ä¼˜åŠ¿

ç›®æ ‡ï¼šè¾¾åˆ°HCMGNNçº§åˆ«çš„æ’åºæ€§èƒ½
- Hit@1: 0.7947
- Hit@3: 0.9417
- Hit@5: 0.9641
- MRR: 0.8712

HCMGNNæ ¸å¿ƒæ€æƒ³ï¼š
1. å¼‚è´¨å›¾å·ç§¯ + å…ƒè·¯å¾„ç‰¹å¾èåˆ
2. intra-subgraph æ¶ˆæ¯ä¼ é€’
3. inter-subgraph èåˆ
4. å¤šå±‚æ¬¡ç‰¹å¾å­¦ä¹ 
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch_geometric.data import HeteroData
from torch_geometric.nn import HeteroConv, SAGEConv, GATConv, Linear
import numpy as np
from sklearn.model_selection import StratifiedKFold
import random
import logging
from datetime import datetime
from collections import defaultdict, deque
import copy
import math

def set_seed(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

class MetaPathExtractor:
    """å…ƒè·¯å¾„æå–å™¨ - æå–æ‰€æœ‰ä»Bacteriaåˆ°Traitçš„è·¯å¾„"""
    
    def __init__(self, hetero_data, max_length=3):
        self.hetero_data = hetero_data
        self.max_length = max_length
        self.edge_types = list(hetero_data.edge_types)
        
    def extract_bacteria_trait_metapaths(self):
        """æå–ä»Bacteriaåˆ°Traitçš„æ‰€æœ‰å…ƒè·¯å¾„"""
        metapaths = []
        
        # ç›´æ¥è·¯å¾„ (é•¿åº¦1)
        for edge_type in self.edge_types:
            src_type, relation, dst_type = edge_type
            if src_type == 'Bacteria' and dst_type == 'Trait':
                metapaths.append([edge_type])
        
        # 2è·³è·¯å¾„
        for first_edge in self.edge_types:
            src1, rel1, dst1 = first_edge
            if src1 == 'Bacteria':
                for second_edge in self.edge_types:
                    src2, rel2, dst2 = second_edge
                    if src2 == dst1 and dst2 == 'Trait':
                        metapaths.append([first_edge, second_edge])
        
        # 3è·³è·¯å¾„
        for first_edge in self.edge_types:
            src1, rel1, dst1 = first_edge
            if src1 == 'Bacteria':
                for second_edge in self.edge_types:
                    src2, rel2, dst2 = second_edge
                    if src2 == dst1:
                        for third_edge in self.edge_types:
                            src3, rel3, dst3 = third_edge
                            if src3 == dst2 and dst3 == 'Trait':
                                metapaths.append([first_edge, second_edge, third_edge])
        
        print(f"å‘ç° {len(metapaths)} æ¡å…ƒè·¯å¾„")
        for i, path in enumerate(metapaths[:10]):  # æ˜¾ç¤ºå‰10æ¡
            path_str = " -> ".join([f"{edge[0]}-{edge[1]}->{edge[2]}" for edge in path])
            print(f"  è·¯å¾„ {i+1}: {path_str}")
        
        return metapaths
    
    def compute_metapath_adjacency(self, metapath):
        """è®¡ç®—å•æ¡å…ƒè·¯å¾„çš„é‚»æ¥çŸ©é˜µ"""
        try:
            # è·å–ç¬¬ä¸€æ¡è¾¹çš„é‚»æ¥çŸ©é˜µ
            first_edge = metapath[0]
            edge_index = self.hetero_data[first_edge].edge_index
            
            num_bacteria = self.hetero_data['Bacteria'].num_nodes
            intermediate_nodes = self.hetero_data[first_edge[2]].num_nodes
            
            # æ„å»ºç¬¬ä¸€è·³çš„é‚»æ¥çŸ©é˜µ
            adj = torch.zeros(num_bacteria, intermediate_nodes)
            adj[edge_index[0], edge_index[1]] = 1.0
            
            # é€æ­¥ç›¸ä¹˜å¾—åˆ°å¤šè·³é‚»æ¥çŸ©é˜µ
            for edge in metapath[1:]:
                edge_index = self.hetero_data[edge].edge_index
                next_nodes = self.hetero_data[edge[2]].num_nodes
                
                next_adj = torch.zeros(intermediate_nodes, next_nodes)
                next_adj[edge_index[0], edge_index[1]] = 1.0
                
                adj = torch.mm(adj, next_adj)
                intermediate_nodes = next_nodes
            
            return adj
            
        except Exception as e:
            print(f"è®¡ç®—å…ƒè·¯å¾„é‚»æ¥çŸ©é˜µå¤±è´¥: {e}")
            # è¿”å›é›¶çŸ©é˜µä½œä¸ºfallback
            num_bacteria = self.hetero_data['Bacteria'].num_nodes
            num_traits = self.hetero_data['Trait'].num_nodes
            return torch.zeros(num_bacteria, num_traits)

class HCMGNNLayer(nn.Module):
    """HCMGNNé£æ ¼çš„å¼‚è´¨å›¾å·ç§¯å±‚"""
    
    def __init__(self, in_dim, out_dim, node_types, edge_types, dropout=0.1):
        super().__init__()
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.dropout = dropout
        
        # èŠ‚ç‚¹ç±»å‹ç‰¹å®šçš„å˜æ¢
        self.node_transforms = nn.ModuleDict()
        for node_type in node_types:
            self.node_transforms[node_type] = nn.Linear(in_dim, out_dim)
        
        # å¼‚è´¨å›¾å·ç§¯ - åªåˆ›å»ºæœ‰æ•ˆçš„è¾¹ç±»å‹çš„å·ç§¯
        conv_dict = {}
        valid_edge_types = []
        
        for edge_type in edge_types:
            src_type, relation, dst_type = edge_type
            # æ£€æŸ¥æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹ç±»å‹æ˜¯å¦å­˜åœ¨
            if src_type in node_types and dst_type in node_types:
                conv_dict[edge_type] = SAGEConv(
                    in_channels=(-1, -1),
                    out_channels=out_dim,
                    normalize=True
                )
                valid_edge_types.append(edge_type)
            else:
                print(f"è·³è¿‡è¾¹ç±»å‹ {edge_type}ï¼Œå› ä¸ºèŠ‚ç‚¹ç±»å‹ä¸å­˜åœ¨")
        
        print(f"æœ‰æ•ˆè¾¹ç±»å‹æ•°é‡: {len(valid_edge_types)}/{len(edge_types)}")
        self.hetero_conv = HeteroConv(conv_dict, aggr='mean')
        
        # å±‚å½’ä¸€åŒ–
        self.layer_norms = nn.ModuleDict()
        for node_type in node_types:
            self.layer_norms[node_type] = nn.LayerNorm(out_dim)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.MultiheadAttention(out_dim, num_heads=4, dropout=dropout)
        
    def forward(self, x_dict, edge_index_dict):
        """å‰å‘ä¼ æ’­"""
        # 1. èŠ‚ç‚¹ç±»å‹ç‰¹å®šå˜æ¢
        transformed_x = {}
        for node_type, x in x_dict.items():
            if x is not None:
                transformed_x[node_type] = self.node_transforms[node_type](x)
            else:
                print(f"è­¦å‘Š: èŠ‚ç‚¹ç±»å‹ {node_type} çš„ç‰¹å¾ä¸º None")
        
        # 2. å¼‚è´¨å›¾å·ç§¯ - åªä½¿ç”¨æœ‰æ•ˆçš„è¾¹ç±»å‹
        valid_edge_index_dict = {}
        for edge_type, edge_index in edge_index_dict.items():
            src_type, _, dst_type = edge_type
            if src_type in transformed_x and dst_type in transformed_x:
                valid_edge_index_dict[edge_type] = edge_index
        
        if not valid_edge_index_dict:
            print("è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„è¾¹ç±»å‹")
            return transformed_x
        
        try:
            conv_out = self.hetero_conv(transformed_x, valid_edge_index_dict)
        except Exception as e:
            print(f"HeteroConv é”™è¯¯: {e}")
            print(f"transformed_x keys: {list(transformed_x.keys())}")
            print(f"valid_edge_index_dict keys: {list(valid_edge_index_dict.keys())}")
            return transformed_x
        
        # 3. æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–
        output = {}
        for node_type in conv_out:
            if node_type in transformed_x:
                # æ®‹å·®è¿æ¥
                residual = transformed_x[node_type] + conv_out[node_type]
                # å±‚å½’ä¸€åŒ–
                output[node_type] = self.layer_norms[node_type](residual)
                # Dropout
                output[node_type] = F.dropout(output[node_type], p=self.dropout, training=self.training)
            else:
                output[node_type] = conv_out[node_type]
        
        return output

class MetaPathAggregator(nn.Module):
    """å…ƒè·¯å¾„èšåˆå™¨ - HCMGNNé£æ ¼çš„å…ƒè·¯å¾„å¤„ç†"""
    
    def __init__(self, embedding_dim, num_metapaths, dropout=0.1):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.num_metapaths = num_metapaths
        
        # å…ƒè·¯å¾„æƒé‡å­¦ä¹ 
        self.metapath_weights = nn.Parameter(torch.ones(num_metapaths))
        
        # å…ƒè·¯å¾„ç‰¹å¾å˜æ¢
        self.metapath_transform = nn.Linear(embedding_dim, embedding_dim)
        
        # æ³¨æ„åŠ›èšåˆ
        self.attention_weights = nn.Parameter(torch.randn(num_metapaths, embedding_dim))
        
        # å±‚å½’ä¸€åŒ–
        self.layer_norm = nn.LayerNorm(embedding_dim)
        
    def forward(self, bacteria_embeddings, trait_embeddings, metapath_matrices):
        """èšåˆå…ƒè·¯å¾„ä¿¡æ¯"""
        # ä¸ºæ¯æ¡å…ƒè·¯å¾„è®¡ç®—ç‰¹å¾
        metapath_features = []
        
        for i, metapath_adj in enumerate(metapath_matrices):
            # é€šè¿‡å…ƒè·¯å¾„é‚»æ¥çŸ©é˜µèšåˆç‰¹å¾
            if metapath_adj.size(0) == bacteria_embeddings.size(0) and metapath_adj.size(1) == trait_embeddings.size(0):
                # æ­£å‘èšåˆ: bacteria -> trait
                aggregated = torch.mm(metapath_adj, trait_embeddings)
                # åå‘èšåˆ: trait -> bacteria  
                reverse_aggregated = torch.mm(metapath_adj.t(), bacteria_embeddings)
                
                # ç»„åˆæ­£åå‘ä¿¡æ¯
                combined = bacteria_embeddings + aggregated
                metapath_features.append(combined)
        
        if metapath_features:
            # å †å æ‰€æœ‰å…ƒè·¯å¾„ç‰¹å¾
            stacked_features = torch.stack(metapath_features, dim=0)  # [num_metapaths, num_bacteria, dim]
            
            # æ³¨æ„åŠ›åŠ æƒèšåˆ
            weights = F.softmax(self.metapath_weights, dim=0)
            weighted_features = torch.sum(stacked_features * weights.view(-1, 1, 1), dim=0)
            
            # å˜æ¢å’Œå½’ä¸€åŒ–
            output = self.metapath_transform(weighted_features)
            output = self.layer_norm(output)
            
            return output
        else:
            return bacteria_embeddings

class HCMGNNBasedMetaPathModel(nn.Module):
    """åŸºäºHCMGNNæ¶æ„çš„å…ƒè·¯å¾„æ¨¡å‹"""
    
    def __init__(self, hetero_data, metapaths, embedding_dim=256, num_layers=3, dropout=0.1):
        super().__init__()
        
        self.hetero_data = hetero_data
        self.metapaths = metapaths
        self.embedding_dim = embedding_dim
        self.num_layers = num_layers
        
        # èŠ‚ç‚¹åˆå§‹åµŒå…¥
        self.node_embeddings = nn.ModuleDict()
        for node_type in hetero_data.node_types:
            num_nodes = hetero_data[node_type].num_nodes
            if hasattr(hetero_data[node_type], 'x') and hetero_data[node_type].x is not None:
                input_dim = hetero_data[node_type].x.size(1)
                self.node_embeddings[node_type] = nn.Linear(input_dim, embedding_dim)
            else:
                self.node_embeddings[node_type] = nn.Embedding(num_nodes, embedding_dim)
        
        # HCMGNNé£æ ¼çš„å¤šå±‚å¼‚è´¨å›¾å·ç§¯
        self.hcmgnn_layers = nn.ModuleList()
        for _ in range(num_layers):
            layer = HCMGNNLayer(
                in_dim=embedding_dim,
                out_dim=embedding_dim,
                node_types=hetero_data.node_types,
                edge_types=hetero_data.edge_types,
                dropout=dropout
            )
            self.hcmgnn_layers.append(layer)
        
        # å…ƒè·¯å¾„èšåˆå™¨
        self.metapath_aggregator = MetaPathAggregator(
            embedding_dim=embedding_dim,
            num_metapaths=len(metapaths),
            dropout=dropout
        )
        
        # æ’åºä¼˜åŒ–çš„æŠ•å½±å±‚
        self.bacteria_proj = nn.Sequential(
            nn.Linear(embedding_dim * 2, embedding_dim),  # *2å› ä¸ºç»“åˆäº†GNNå’Œå…ƒè·¯å¾„ç‰¹å¾
            nn.LayerNorm(embedding_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(embedding_dim, embedding_dim // 2)
        )
        
        self.trait_proj = nn.Sequential(
            nn.Linear(embedding_dim, embedding_dim),
            nn.LayerNorm(embedding_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(embedding_dim, embedding_dim // 2)
        )
        
        # æ¸©åº¦å‚æ•°å’Œç›¸ä¼¼åº¦è®¡ç®—
        self.temperature = nn.Parameter(torch.tensor(20.0))  # æ›´é«˜çš„æ¸©åº¦ç”¨äºsharperåˆ†å¸ƒ
        self.similarity_bias = nn.Parameter(torch.tensor(0.0))
        
        # é¢„è®¡ç®—å…ƒè·¯å¾„é‚»æ¥çŸ©é˜µ
        self.metapath_matrices = self._precompute_metapath_matrices()
        
        self._init_weights()
    
    def _precompute_metapath_matrices(self):
        """é¢„è®¡ç®—æ‰€æœ‰å…ƒè·¯å¾„çš„é‚»æ¥çŸ©é˜µ"""
        extractor = MetaPathExtractor(self.hetero_data)
        matrices = []
        
        for metapath in self.metapaths:
            adj_matrix = extractor.compute_metapath_adjacency(metapath)
            matrices.append(adj_matrix)
        
        return matrices
    
    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                nn.init.normal_(module.weight, std=0.1)
    
    def get_initial_embeddings(self):
        """è·å–èŠ‚ç‚¹åˆå§‹åµŒå…¥"""
        x_dict = {}
        device = next(self.parameters()).device
        
        for node_type in self.hetero_data.node_types:
            try:
                if hasattr(self.hetero_data[node_type], 'x') and self.hetero_data[node_type].x is not None:
                    x = self.hetero_data[node_type].x.to(device)
                    if x.dim() == 2 and x.size(1) > 0:
                        x_dict[node_type] = self.node_embeddings[node_type](x)
                    else:
                        print(f"è­¦å‘Š: èŠ‚ç‚¹ç±»å‹ {node_type} çš„ç‰¹å¾ç»´åº¦å¼‚å¸¸: {x.shape}")
                        # ä½¿ç”¨embeddingä½œä¸ºfallback
                        num_nodes = self.hetero_data[node_type].num_nodes
                        node_indices = torch.arange(num_nodes, device=device)
                        x_dict[node_type] = self.node_embeddings[node_type](node_indices)
                else:
                    num_nodes = self.hetero_data[node_type].num_nodes
                    node_indices = torch.arange(num_nodes, device=device)
                    x_dict[node_type] = self.node_embeddings[node_type](node_indices)
            except Exception as e:
                print(f"å¤„ç†èŠ‚ç‚¹ç±»å‹ {node_type} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                # ä½¿ç”¨embeddingä½œä¸ºfallback
                num_nodes = self.hetero_data[node_type].num_nodes
                node_indices = torch.arange(num_nodes, device=device)
                x_dict[node_type] = self.node_embeddings[node_type](node_indices)
        
        return x_dict
    
    def forward(self):
        """å‰å‘ä¼ æ’­"""
        device = next(self.parameters()).device
        
        # 1. è·å–åˆå§‹åµŒå…¥
        x_dict = self.get_initial_embeddings()
        edge_index_dict = {k: v.to(device) for k, v in self.hetero_data.edge_index_dict.items()}
        
        # 2. å¤šå±‚HCMGNN
        for layer in self.hcmgnn_layers:
            x_dict = layer(x_dict, edge_index_dict)
        
        # 3. è·å–ç»†èŒå’Œæ€§çŠ¶çš„GNNåµŒå…¥
        bacteria_gnn_emb = x_dict['Bacteria']
        trait_gnn_emb = x_dict['Trait']
        
        # 4. å…ƒè·¯å¾„èšåˆ
        metapath_matrices_device = [m.to(device) for m in self.metapath_matrices]
        bacteria_metapath_emb = self.metapath_aggregator(
            bacteria_gnn_emb, trait_gnn_emb, metapath_matrices_device
        )
        
        # 5. ç‰¹å¾èåˆ (GNN + å…ƒè·¯å¾„)
        bacteria_combined = torch.cat([bacteria_gnn_emb, bacteria_metapath_emb], dim=1)
        
        return bacteria_combined, trait_gnn_emb
    
    def compute_ranking_scores(self, bacteria_embeddings, trait_embeddings):
        """è®¡ç®—æ’åºåˆ†æ•°"""
        # æŠ•å½±åˆ°æ’åºç©ºé—´
        bacteria_proj = self.bacteria_proj(bacteria_embeddings)
        trait_proj = self.trait_proj(trait_embeddings)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        scores = torch.mm(bacteria_proj, trait_proj.t())
        
        # æ¸©åº¦ç¼©æ”¾å’Œåç§»
        scores = scores * self.temperature + self.similarity_bias
        
        return scores

class EnhancedRankingLoss(nn.Module):
    """å¢å¼ºçš„æ’åºæŸå¤±å‡½æ•° - å€Ÿé‰´HCMGNNçš„æŸå¤±è®¾è®¡"""
    
    def __init__(self, margin=2.0, lambda_param=0.5):
        super().__init__()
        self.margin = margin
        self.lambda_param = lambda_param  # ç±»ä¼¼HCMGNNä¸­çš„Î³å‚æ•°
        
    def forward(self, scores, positive_pairs):
        """
        è®¡ç®—æŸå¤±ï¼Œç±»ä¼¼HCMGNNçš„æŸå¤±å‡½æ•°
        L = (1-Î»)||y âŠ™ (y-Å·)||Â² + Î»||(1-y) âŠ™ (y-Å·)||Â²
        """
        device = scores.device
        num_bacteria, num_traits = scores.shape
        
        # æ„å»ºæ ‡ç­¾çŸ©é˜µ
        labels = torch.zeros_like(scores)
        for bacteria_id, trait_id in positive_pairs:
            labels[bacteria_id, trait_id] = 1.0
        
        # HCMGNNé£æ ¼çš„æŸå¤±
        predictions = torch.sigmoid(scores)
        diff = labels - predictions
        
        # æ­£æ ·æœ¬æŸå¤±
        positive_loss = torch.sum(labels * (diff ** 2))
        
        # è´Ÿæ ·æœ¬æŸå¤±
        negative_loss = torch.sum((1 - labels) * (diff ** 2))
        
        # ç»„åˆæŸå¤±
        total_samples = num_bacteria * num_traits
        positive_loss = positive_loss / total_samples
        negative_loss = negative_loss / total_samples
        
        loss = (1 - self.lambda_param) * positive_loss + self.lambda_param * negative_loss
        
        # æ·»åŠ æ’åºæŸå¤±
        ranking_loss = 0.0
        num_ranking_pairs = 0
        
        for bacteria_id, pos_trait_id in positive_pairs:
            pos_score = scores[bacteria_id, pos_trait_id]
            neg_scores = scores[bacteria_id, labels[bacteria_id] == 0]
            
            if len(neg_scores) > 0:
                # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„è´Ÿæ ·æœ¬è¿›è¡Œå¯¹æ¯”
                top_neg_scores = torch.topk(neg_scores, min(5, len(neg_scores))).values
                for neg_score in top_neg_scores:
                    ranking_loss += F.relu(self.margin - (pos_score - neg_score))
                    num_ranking_pairs += 1
        
        if num_ranking_pairs > 0:
            ranking_loss = ranking_loss / num_ranking_pairs
            loss = loss + 0.3 * ranking_loss
        
        return loss

class HCMGNNTrainer:
    """åŸºäºHCMGNNæ¶æ„çš„è®­ç»ƒå™¨"""
    
    def __init__(self, hetero_data, positive_pairs, device='cuda'):
        self.hetero_data = hetero_data.to(device)
        self.positive_pairs = positive_pairs
        self.device = device
        
        # è®¾ç½®æ—¥å¿— (å¿…é¡»å…ˆè®¾ç½®ï¼Œå› ä¸ºåç»­æ–¹æ³•ä¼šç”¨åˆ°)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_filename = f"hcmgnn_metapath_{timestamp}.log"
        
        # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
        self.save_dir = f"hcmgnn_models_{timestamp}"
        os.makedirs(self.save_dir, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(os.path.join(self.save_dir, self.log_filename)),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"HCMGNNå…ƒè·¯å¾„æ¨¡å‹è®­ç»ƒå¼€å§‹ï¼Œæ—¥å¿—æ–‡ä»¶: {os.path.join(self.save_dir, self.log_filename)}")
        self.logger.info(f"æ¨¡å‹ä¿å­˜ç›®å½•: {self.save_dir}")
        
        # æå–å…ƒè·¯å¾„
        extractor = MetaPathExtractor(hetero_data)
        self.metapaths = extractor.extract_bacteria_trait_metapaths()
        
        # æ•°æ®åˆ’åˆ†
        self._split_data()
    
    def _split_data(self):
        """æ•°æ®åˆ’åˆ† - ä½¿ç”¨ç®€å•éšæœºåˆ’åˆ†é¿å…StratifiedKFoldçš„é—®é¢˜"""
        random.shuffle(self.positive_pairs)
        
        # 80%è®­ç»ƒï¼Œ20%éªŒè¯
        split_idx = int(0.8 * len(self.positive_pairs))
        self.train_pairs = self.positive_pairs[:split_idx]
        self.val_pairs = self.positive_pairs[split_idx:]
        
        self.logger.info(f"è®­ç»ƒæ ·æœ¬: {len(self.train_pairs)}, éªŒè¯æ ·æœ¬: {len(self.val_pairs)}")
    
    def compute_ranking_metrics(self, model):
        """è®¡ç®—æ’åºæŒ‡æ ‡"""
        model.eval()
        
        with torch.no_grad():
            bacteria_embeddings, trait_embeddings = model()
            scores = model.compute_ranking_scores(bacteria_embeddings, trait_embeddings)
            
            metrics = self._compute_metrics(scores, self.val_pairs)
        
        return metrics
    
    def _compute_metrics(self, scores, positive_pairs):
        """è®¡ç®—æ’åºæŒ‡æ ‡"""
        metrics = {
            'hit_1': 0.0,
            'hit_3': 0.0,
            'hit_5': 0.0,
            'hit_10': 0.0,
            'mrr': 0.0,
            'mean_rank': 0.0
        }
        
        bacteria_groups = defaultdict(list)
        for bacteria_id, trait_id in positive_pairs:
            bacteria_groups[bacteria_id].append(trait_id)
        
        total_queries = 0
        
        for bacteria_id, positive_traits in bacteria_groups.items():
            bacteria_scores = scores[bacteria_id]
            sorted_trait_indices = torch.argsort(bacteria_scores, descending=True)
            
            for trait_id in positive_traits:
                rank_tensor = (sorted_trait_indices == trait_id).nonzero(as_tuple=True)[0]
                if len(rank_tensor) > 0:
                    rank = rank_tensor.item() + 1
                    
                    metrics['hit_1'] += 1 if rank <= 1 else 0
                    metrics['hit_3'] += 1 if rank <= 3 else 0
                    metrics['hit_5'] += 1 if rank <= 5 else 0
                    metrics['hit_10'] += 1 if rank <= 10 else 0
                    metrics['mrr'] += 1.0 / rank
                    metrics['mean_rank'] += rank
                    
                    total_queries += 1
        
        if total_queries > 0:
            for key in metrics:
                metrics[key] /= total_queries
        
        return metrics
    
    def train_epoch(self, model, optimizer, loss_fn):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        model.train()
        
        bacteria_embeddings, trait_embeddings = model()
        scores = model.compute_ranking_scores(bacteria_embeddings, trait_embeddings)
        
        loss = loss_fn(scores, self.train_pairs)
        
        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        return loss.item()
    
    def train(self, config):
        """è®­ç»ƒæ¨¡å‹"""
        self.logger.info(f"å¼€å§‹è®­ç»ƒé…ç½®: {config['name']}")
        self.logger.info(f"å…ƒè·¯å¾„æ•°é‡: {len(self.metapaths)}")
        
        model = HCMGNNBasedMetaPathModel(
            hetero_data=self.hetero_data,
            metapaths=self.metapaths,
            embedding_dim=config['embedding_dim'],
            num_layers=config['num_layers'],
            dropout=config['dropout']
        ).to(self.device)
        
        loss_fn = EnhancedRankingLoss(
            margin=config.get('margin', 2.0),
            lambda_param=config.get('lambda_param', 0.5)
        )
        
        optimizer = optim.AdamW(
            model.parameters(),
            lr=config['lr'],
            weight_decay=config['weight_decay']
        )
        
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=config['epochs'], eta_min=config['lr'] * 0.01
        )
        
        best_mrr = 0.0
        best_metrics = None
        patience_counter = 0
        
        for epoch in range(config['epochs']):
            train_loss = self.train_epoch(model, optimizer, loss_fn)
            scheduler.step()
            
            if epoch % 20 == 0:
                val_metrics = self.compute_ranking_metrics(model)
                
                if val_metrics['mrr'] > best_mrr:
                    best_mrr = val_metrics['mrr']
                    best_metrics = val_metrics.copy()
                    patience_counter = 0
                else:
                    patience_counter += 1
                
                self.logger.info(
                    f"Epoch {epoch:3d}: Loss={train_loss:.4f}, MRR={val_metrics['mrr']:.4f}, "
                    f"Hit@1={val_metrics['hit_1']:.4f}, Hit@3={val_metrics['hit_3']:.4f}"
                )
                
                if patience_counter >= config.get('patience', 25):
                    self.logger.info(f"Early stopping at epoch {epoch}")
                    break
        
        return best_metrics

def main():
    """ä¸»å‡½æ•°"""
    set_seed(42)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    data_path = "/user_data/yezy/zhangjm/FE_kg/Merge/heterodata_reason0725/hetero_graph0725_standardized.pt"
    print(f"åŠ è½½æ•°æ®: {data_path}")
    hetero_data = torch.load(data_path, map_location='cpu', weights_only=False)
    
    # è·å–æ‰€æœ‰Bacteriaåˆ°Traitçš„æ­£æ ·æœ¬ï¼ˆåˆå¹¶æ‰€æœ‰å…³ç³»ç±»å‹ï¼‰
    all_bacteria_trait_edges = []
    
    # æ”¶é›†æ‰€æœ‰Bacteria->Traitçš„è¾¹
    bacteria_trait_relations = [
        ('Bacteria', 'related_to', 'Trait'),
        ('Bacteria', 'positive_relate', 'Trait'),
        ('Bacteria', 'negative_relate', 'Trait')
    ]
    
    for edge_type in bacteria_trait_relations:
        if edge_type in hetero_data.edge_types:
            edges = hetero_data[edge_type].edge_index.t()
            all_bacteria_trait_edges.append(edges)
            print(f"  {edge_type}: {edges.shape[0]} æ¡è¾¹")
    
    # åˆå¹¶æ‰€æœ‰è¾¹
    bacteria_trait_edges = torch.cat(all_bacteria_trait_edges, dim=0)
    positive_pairs = [(int(edge[0]), int(edge[1])) for edge in bacteria_trait_edges]
    
    logger = logging.getLogger(__name__)
    logger.info(f"æ­£æ ·æœ¬æ•°é‡: {len(positive_pairs)}")
    logger.info(f"ç»†èŒèŠ‚ç‚¹: {hetero_data['Bacteria'].num_nodes}")
    logger.info(f"æ€§çŠ¶èŠ‚ç‚¹: {hetero_data['Trait'].num_nodes}")
    
    # HCMGNNç›®æ ‡åŸºå‡†
    target_metrics = {
        'hit_1': 0.7947,
        'hit_3': 0.9417,
        'hit_5': 0.9641,
        'mrr': 0.8712,
        'mean_rank': 1.5  # ä¼°è®¡å€¼
    }
    
    logger.info("HCMGNNç›®æ ‡åŸºå‡†:")
    for metric, value in target_metrics.items():
        logger.info(f"  {metric}: {value:.4f}")
    
    # è®­ç»ƒé…ç½® - é’ˆå¯¹HCMGNNæ¶æ„ä¼˜åŒ–
    configs = [
        {
            'name': 'HCMGNN-Large',
            'embedding_dim': 512,
            'num_layers': 4,
            'dropout': 0.1,
            'lr': 0.0005,
            'weight_decay': 1e-5,
            'epochs': 400,
            'patience': 30,
            'margin': 2.0,
            'lambda_param': 0.7
        },
        {
            'name': 'HCMGNN-Medium', 
            'embedding_dim': 256,
            'num_layers': 3,
            'dropout': 0.15,
            'lr': 0.001,
            'weight_decay': 1e-4,
            'epochs': 300,
            'patience': 25,
            'margin': 1.5,
            'lambda_param': 0.5
        },
        {
            'name': 'HCMGNN-Compact',
            'embedding_dim': 128,
            'num_layers': 2,
            'dropout': 0.2,
            'lr': 0.002,
            'weight_decay': 5e-4,
            'epochs': 200,
            'patience': 20,
            'margin': 1.0,
            'lambda_param': 0.3
        }
    ]
    
    trainer = HCMGNNTrainer(hetero_data, positive_pairs, device)
    
    best_overall = None
    best_config_name = None
    
    for config in configs:
        logger.info(f"\n======== é…ç½®: {config['name']} ========")
        
        try:
            metrics = trainer.train(config)
            
            logger.info(f"é…ç½® {config['name']} ç»“æœ:")
            score = 0.0
            exceeded_count = 0
            
            for metric, value in metrics.items():
                target_value = target_metrics.get(metric, 0)
                exceeded = value >= target_value if metric != 'mean_rank' else value <= target_value
                status = "âœ…" if exceeded else "âŒ"
                
                if exceeded:
                    exceeded_count += 1
                
                logger.info(f"  {metric}: {value:.4f} (ç›®æ ‡: {target_value:.4f}) {status}")
                
                # è®¡ç®—ç»¼åˆå¾—åˆ†
                if metric == 'mrr':
                    score += value * 0.4
                elif metric == 'hit_1':
                    score += value * 0.3
                elif metric == 'hit_3':
                    score += value * 0.2
                elif metric == 'hit_5':
                    score += value * 0.1
            
            logger.info(f"  ç»¼åˆå¾—åˆ†: {score:.4f}")
            logger.info(f"  è¶…è¶ŠHCMGNNæŒ‡æ ‡æ•°: {exceeded_count}/{len(target_metrics)}")
            
            if best_overall is None or score > best_overall.get('ç»¼åˆå¾—åˆ†', 0):
                best_overall = metrics.copy()
                best_overall['ç»¼åˆå¾—åˆ†'] = score
                best_overall['é…ç½®åç§°'] = config['name']
                best_overall['è¶…è¶ŠæŒ‡æ ‡æ•°'] = exceeded_count
                best_config_name = config['name']
        
        except Exception as e:
            logger.error(f"é…ç½® {config['name']} è®­ç»ƒå¤±è´¥: {e}")
            continue
    
    # æœ€ç»ˆç»“æœ
    logger.info("\n" + "="*60)
    logger.info("ğŸ† æœ€ç»ˆæœ€ä½³ç»“æœ (å¯¹æ¯”HCMGNN)")
    logger.info("="*60)
    
    if best_overall:
        logger.info(f"ğŸ¥‡ æœ€ä½³é…ç½®: {best_config_name}")
        logger.info(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”HCMGNN:")
        
        for metric, value in best_overall.items():
            if metric in target_metrics:
                target_value = target_metrics[metric]
                diff = value - target_value
                pct_diff = (diff / target_value) * 100 if target_value != 0 else 0
                exceeded = value >= target_value if metric != 'mean_rank' else value <= target_value
                status = "âœ…" if exceeded else "âŒ"
                logger.info(f"  {metric}: {value:.4f} vs HCMGNN {target_value:.4f} {status} {diff:+.4f} ({pct_diff:+.1f}%)")
        
        logger.info(f"\nğŸ¯ ç›¸å¯¹HCMGNNè¡¨ç°:")
        logger.info(f"  {'âœ…' if best_overall['è¶…è¶ŠæŒ‡æ ‡æ•°'] >= 3 else 'âš ï¸'} è¶…è¶ŠHCMGNN: {best_overall['è¶…è¶ŠæŒ‡æ ‡æ•°']}/{len(target_metrics)} ä¸ªæŒ‡æ ‡")
        
        # åˆ¤æ–­æ˜¯å¦è¾¾åˆ°HCMGNNæ°´å¹³
        mrr_good = best_overall['mrr'] >= target_metrics['mrr'] * 0.95  # 95%çš„HCMGNNæ€§èƒ½
        hit1_good = best_overall['hit_1'] >= target_metrics['hit_1'] * 0.95
        
        if mrr_good and hit1_good:
            logger.info("  ğŸ‰ æˆåŠŸè¾¾åˆ°HCMGNNçº§åˆ«æ€§èƒ½ï¼")
        else:
            logger.info("  âš ï¸ å°šæœªå®Œå…¨è¾¾åˆ°HCMGNNæ°´å¹³ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    logger.info(f"\nğŸ”š è®­ç»ƒå®Œæˆï¼æ—¥å¿—æ–‡ä»¶: {trainer.log_filename}")

if __name__ == "__main__":
    main()
